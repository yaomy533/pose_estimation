writen by 姚梦阳

# AMB-HAND 人手数据集手势、位姿优化

## 1. 人手位姿优化

### 1.0 初始位姿

采用Umeyama algorithm和RANSAC算法得到的初步位姿：$P_{ori}=\left\{s*R|T\right\}$​，以及用其他方法得到的模型$M_l$​。​​​​

<img src=".\实验图\ori_mask.png" alt="ori_mask" style="zoom:22%;" />

### 1.1 方案一：Mask+Coarse+Refine

**Coarse：**根据初始位姿$P_{ori}$​​​​采用遗传算法进行初步优化(coarse)得到$K(=16)$​​​​组初步位姿的**偏移量：**$\left\{P_{coa}^{i}\right\}_{i=1}^K$​​​​​​。

**Refine：**对$K$​​​​组初步位姿$\left\{P_{coa}^{i}\right\}_{i=1}^K$​​​​采用梯度下降进行精度优化，得到$K$​​​​组精确位姿的**偏移量：**$\left\{P_{ref}^{i}\right\}_{i=1}^K$​​​​。

**Loss：**将优化的位姿$\left\{P_{opt}^{i}\right\}_{i=1}^K$​作用到人手模型$M_l$​上，经过透视投影可以得到四个视角的掩码$\left\{mask_{p}^{j}\right\}_{j=1}^4$​，通过MaskRCNN得到对应四组视角的掩码为$\left\{mask_{o}^{j}\right\}_{j=1}^4$​​，所以我们的损失函数可以表示为：
$$
L_m=\sum (1-IOU(mask_o,mask_p))
$$


在这一方案中，我尝试了很多种策略，包括：

+ 调整视角权重
+ 在Coarse阶段对周围采样而不是全局采样
+ 调整损失函数：1-iou->log(iou)、 直接mask相减求和

这些策略对于效果提升都不明显或者更差，只能对初始位姿的手势优化效果好，初始效果差**尤其是R**则优化效果很差。

结果存在以下问题：

+ 旋转角偏差较大无法调整回来
+ 结果存在180度偏差的情况

<img src=".\实验图\rt_方案一.png" alt="rt_方案一" style="zoom:27%;" />

### 1.2 方案二：加入初始位移微调

根据理论推断，coarse阶段的遗传算法是根据蒙特卡洛采样方式的逐步细化的方式进行优化的，这种方法对于R的优化效果较好，但是对于T的优化效果并不理想，Latentfusion在用的时候也是在真实的T上加上一些噪声用的。而refine这种算法相比较优化R在优化T的时候有更少的局部最优。

​		根据上述分析，**我在Coarse步骤之前加入了对于原始位姿$P_{ori}$​中的$T_{ori}$​的优化**，得到一组较好的$T$​，注意这次不是优化的偏移量，而是直接对T进行优化得到一组比较准的位移$T_{pre}$​。

**Coarse：**根据$T_{pre}$​以及对整个旋转空间进行均匀采样，得到$K(=16)$​组初步位姿：$\left\{P_{coa}^{i}\right\}_{i=1}^K$​。**注意不是偏移量了，下同。**

**Refine：**对$K$​​​​组初步位姿$\left\{P_{coa}^{i}\right\}_{i=1}^K$​​​​采用梯度下降进行精度优化，得到$K$​​​​组精确位姿：$\left\{P_{ref}^{i}\right\}_{i=1}^K$​​​​。

**Loss：**没有变化
$$
L_m=\sum_{K}\sum_{views} (1-IOU(mask_o,mask_p))
$$
得到的结果相较于之前有了明显的提升，平均每个视角的iou到0.775。（第一个视角比较准能到0.8-0.9的样子，后面三个视角相对来说较差），但是**还是会存在结果出现180度偏差的情况**。

<img src=".\实验图\rt_方案二.png" alt="rt_方案二" style="zoom:150%;" />

### 1.3 方案三：加入Joint损失

OpenPose得到的四个视角关节点$J_o$​​，以及根据预测位姿$P$和人手模型$M$​​​​得到的四个视角的关节点$J_p$计算损失：
$$
L_j= \sum_{K}\sum_{views}\sum_{points} tanh((J_p - J_o)^2)
$$
通过$L_j$​约束180度误差的情况，并进一步的对位姿的优化做指导，[结果](.\实验图\方案三)。

### 1.4 方案四： 加快优化速度

优化策略主要的时间在于遗传算法每一轮迭代需要进行192次渲染，一次迭代需要12s，在梯度下降每次迭代是渲染16组数据，需要1s，所以整体的时间比较慢。对此，我们利用相邻帧之间位姿变化很小的这一特点，将上一帧的最优输入到下一帧直接进行梯度下降，大概20~30s可以优化一帧。

![GIF20210925161019](.\实验图\方案四\GIF20210925161019.gif)



